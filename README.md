
# RestaurantGPT ğŸ½ï¸ğŸ¤–

![Python Restaurant](image/Python_restaurant.png)


**RestaurantGPT** is a live simulation of a restaurant, developed with OpenAI Agents, where customers order, waiters take orders, and entertainers entertain guests, all powered by a Language Model (LLM) backend.

This project combines **Python**, **Open AI agents**, **Tkinter GUI**, and **Object Oriented Programming** to create a dynamic restaurant environment where human-like decisions happen in real-time.

---

## âœ¨ Features
- **Queue Handling**: we have X tables, and customers will come to sit, if they can. This logic is implemented.
- **Dynamic Customer Behavior**: Customers generate natural conversation with waiters using an LLM to order or ask for suggestions.
- **Real-Time Event Simulation**: Cooking, eating, waiting, and customer departures are simulated based on how long it will take for them to eat the food they ordered.
- **Smart Query Handling**: Customers waiting in line or at the table can ask questions ("How long until my food?"), and an entertainer LLM agent answers them.
- **Live GUI Dashboard**:
  - See which tables are free or occupied.
  - Watch customer interactions live.
  - Time clock and event feed.
- **Log File**: All actions are logged cleanly in `restaurant_log.txt`.

---

## ğŸ“‚ Folder Structure

```
RestaurantGPT/
â”œâ”€â”€ constants.py        # Menu items, customer names, and system constants
â”œâ”€â”€ custom_agents.py    # Specialized agents (customer, waiter, entertainer)
â”œâ”€â”€ llm_models.py       # Core restaurant simulation logic
â”œâ”€â”€ llm_models_gui.py   # GUI application logic (Tkinter)
â”œâ”€â”€ utils.py            # Utility functions (menu preprocessing, JSON extraction)
â”œâ”€â”€ restaurant_log.txt  # Auto-generated event log
â”œâ”€â”€ README.md           # (this file)
â””â”€â”€ requirements.txt    # Required Python libraries
```

---

## ğŸš€ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

Youâ€™ll need:
- `tk`
- `openai`
- `agents`
- `asyncio`
- `httpx`

### 2. Set up your environment

You need an OpenAI-compatible API key:

```bash
export OPENAI_API_KEY="your-openai-api-key-here"
```

Or configure it in a `.env` file.

### 3. Launch the Simulation

```bash
python llm_models_gui.py
```

âœ… A live GUI window will open, showing tables, event feed, and simulation clock.

---

## ğŸ› ï¸ Customization

- **Menu**: Edit `constants.py` (see `MENU_FILE`).
- **Simulation parameters**: You can adjust all the parameters of the restaurant (e.g., number of tables) and the Menu through a .csv file.
- **Customer Queries**: Tune `query_prob` to control how often customers ask questions.
- **Tick Length**: Modify `tick_length` to speed up or slow down the simulation.

---

## ğŸ“¸ Preview

[12:31:23] The customer Emma is talking to the waiter, saying this I'd like to start with the **Bruschetta** for the appetizer. Then, I'll have the **Spaghetti Carbonara** for the first course. For dessert, I'll enjoy the **Tiramisu**. 

Could you also recommend a wine to go with this meal?
[12:31:25] The processed response from our LLM is {'food': ['Bruschetta', 'Spaghetti Carbonara', 'Tiramisu', 'Chianti Classico'], 'status': 'successful'}
[12:31:25] [0000m] â“ Customer 1: How long will the food take me?
[12:31:25] [0000m] â¡ï¸ Estimated food wait for customer 1: 15m
[12:31:26] Our LLM took care of Emma with this: RunResult:
- Last agent: Agent(name="Entertainer", ...)
- Final output (str):
    Hi Emma! Thank you for your patience. The wait to get in is about 15 minutes. Almost thereâ€”just enough time to start dreaming about that delicious Risotto alla Milanese! ğŸ½ï¸
- 1 new item(s)
- 1 raw response(s)
- 0 input guardrail result(s)
- 0 output guardrail result(s)
(See `RunResult` for more details)
[12:31:31] The customer Liam is talking to the waiter, saying this I'd like to start with a **Bruschetta**, followed by the **Spaghetti Carbonara**. Could I also have a glass of **Chianti Classico** wine? For dessert, I'll have the **Tiramisu**. Thank you!
[12:31:33] The processed response from our LLM is {'food': ['Bruschetta', 'Spaghetti Carbonara', 'Chianti Classico', 'Tiramisu'], 'status': 'successfull'}


## ğŸ¤” Future Plans

- Animated progress bars for cooking and eating phases ğŸ”ğŸ“Š
- Pause/Resume functionality from GUI
- Different customer personalities (angry, impatient, polite)
- Guardrails on LLM Agents for consistency
- Customer satisfaction Agents after lunch.

---

## ğŸ“œ License

Released under the MIT License.

---

## ğŸ™ Credits

Built with â¤ï¸ by [Piero Paialunga](https://github.com/PieroPaialungaAI).
